{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy Stats Jupter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scipy stats is a module contained within the scipy python package. This sub package is used to carry out statistical analysis of datasets in a quick and easy to use manner. This module consists of a library of ever growing statistical tests and functions, probability distributions, kernal density estimation and much more [1]. Due to the large size of this library it would be very difficult to describe each function within it and so I am going to run through a few of the features of the scipy.stats module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will start first by importing all the necessary packages to describe the features. [2],[3],[4],[5].\n",
    "import numpy as np \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first feature of she scipy.stats package I am going to describe is the probability distributions. In scipy.stats these are separated into three headings. These are Continuous distributions, Multivariate distributions and Discrete Distributions.\n",
    "\n",
    "#### The one I will be looking at is a uniform distribution. This type of distribution is one in which each value within a certain range is equally likely to occur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will start by generating 10,000 numbers from a uniform distribution using the stats package.\n",
    "uniform= stats.uniform.rvs(size= 10000, loc= 0, scale= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will now place them in a pandas dataframe and generate a plot\n",
    "pd.DataFrame(uniform).plot(kind=\"density\", figsize= (9,9), xlim= (-1,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now be looking at the cumalative distribution function in regards to the uniform distribution. This is another feature of the stats package. This function allows us to determine whether an observation falls below a specified value. In the below function this specified value is x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use x= 2.5 as the cut off value and expect an answer of 0.25 or 25% as it should be a quarter of the scale due the uniform\n",
    "# distribution\n",
    "stats.uniform.cdf(x= 2.5, loc= 0, scale= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now be looking at the percent point function in regards to the uniform distribution. This function is the inverse of the CDF function and returns the cut-off for which we have a certain percentage chance for drawing an observation below that value. The percentage example I will use here is 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.uniform.ppf(q= 0.75, loc= 0, scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final function associated with the uniform distribution I will look at is the Probability Density Function (PDF). The PDF gives the probability density otherwise known as the height of the distribution at a given x value. Due to the fact that the Uniform Distribution is flat, all x values within its range will have the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below for loop will print the densitys between -1 and 11 \n",
    "for x in range (-1, 12, 2):\n",
    "    print(\"Density at x value \" + str(x))\n",
    "    print(stats.uniform.pdf(x, loc= 0, scale= 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scipy.stats offer a large variety of statistical functions that can be carried out on datasets all of which can be seen at https://docs.scipy.org/doc/scipy/reference/stats.html#summary-statistics. I will display a few of them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first statistical function will look at is the find_repeats function\n",
    "stats.find_repeats([1,2,3,4,4,4,4,3,2,1,2,3,57,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above function will find the number of repeats in an array and return two arrays. The first will show the numbers that repeated and the second will show the number of repeats in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second statistical function I will look at is the describe function.\n",
    "# I will start by generating a numpy array of 20 numbers\n",
    "x= np.arange(20)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will then call the .describe function\n",
    "stats.describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above function will return the nobs, which is the size of the array, the min and max of the array, the mean of the array, the variance, which is a measure of dispersion, the skewness which is the degree of asymmetry in the array and the Kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another stats function is the tmax.\n",
    "# I will again create another numpy array of length 20.\n",
    "x= np.arange(20)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will now now run the tmax function on the array\n",
    "stats.tmax(x, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above function calculates the max value of the array while ignoring the upperlimit in the above case 11 and anything above it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova stands for analysis of variance and is a method used in statistical analysis to test 3 or more groups for mean differences of continueous response variables [6]. There are two types of ANOVA, these are one-way ANOVA and two-way ANOVA. One-way ANOVA. A one-way ANOVA is used to compare a single dependant variable with a single independant variable also known a a category. A two-way ANOVA is used to compare a single dependant variable with 2 and more independant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### One-way ANOVA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to carry out a one-way ANOVA there are 6 assumptions that must be met in order to ensure that the data is suitable for this type of test. The 6 assumptions are:\n",
    "\n",
    "#### 1) The dependant variable must be measured at the interval level meaning they are continueous.\n",
    "#### 2) The independant variable must conpose of more than 1 groups.\n",
    "#### 3) There should be 'independance of observations' which means that the observations should not be related to the group or      there should be no relationship between the groups.\n",
    "#### 4) There should be no outliers. This is data that deviates greatly from the mean and do not follow any particular pattern.\n",
    "#### 5) The dependant variable must be 'normally distributed' for each category of the independant variable. We will use a Shapiro-Wilk to test for this.\n",
    "#### 6) There most be homogeneity of variances. This can be determined by carrying out the Levenes test for homogeneity of variance. [7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I start by importing the necessary python packages to carry out the One-way ANOVA.\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# I then load the dataset I will be using to demonstrate the ANOVA method [8].\n",
    "df = pd.read_csv(\"data/Diet.csv\")\n",
    "df\n",
    "# I will now change the Diet column to a string to make it easier to use later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above dataset is an analysis of the results that people obtain after a period of 6 weeks on 3 different types of diet. This dataset fufills the necessary requirements outlined in the first four assumptions of the one-way ANOVA test. For the above dataset I am going to use one-way ANOVA to determine which diet was better for weightloss. In this instance the dependant variable is the weightloss6weeks and the independant variable is the Diet. I now determine whether the above data is suitable for a one-way ANOVA based on assumption 4. I will determine whether or not there are any outliers in the variable I will be investigating. I will do this using a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I first select the column I will be working it and give it the variable name 'dependant'.\n",
    "dependant = df[\"weightloss6weeks\"]\n",
    "independant = df[\"Diet\"].astype('category')\n",
    "\n",
    "# I will now change the Diet column to a category to allow me to show the boxplot below for all 3 diets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will then import seaborn in order to generate a boxplot.\n",
    "import seaborn as sns\n",
    "# I call the command to generate the boxplot.\n",
    "sns.boxplot(dependant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen from the above boxplot, there are no outliers within the dependant variable weightloss6weeks. I will now separate the weightloss6weeks into the 3 diet groups to check for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time I will plot both the dependant and independant variables. This should produce 3 boxplot, each one representing\n",
    "# a diet\n",
    "sns.boxplot(dependant, independant);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen from the above plot there are two outliers in relation to diet 1. Due to the nature of this dataset it is likely that these outliers are genuine as there are much more factors involved in weightloss that vary between individuals then only the factors explored in this dataset for example food intolerances, individuals metabolism and activity level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next thing I am going to do is check for assumption 5 being present in the dataset. In order to do this I will run a Shapiro-Wilk to ensure that my dependant variable weightloss6weeks is normally distributed. Prior to doing this I will plot a distribution plot again using the seaborn library to get a visual idea as to whether or not the depentant variable is of normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=dependant, hue=independant, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now carry out the Shapiro-Wilk test on the data to verify the dependant variable is normally distributed.\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll first need to seperate the weightloss6weeks data into groups based on the diet\n",
    "wtl_len_one = dependant[independant ==1]\n",
    "wtl_len_two = dependant[independant == 2]\n",
    "wtl_len_three = dependant[independant == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now run the Shaprio-Wilk test on these three pieces of data.\n",
    "\n",
    "ss.shapiro(wtl_len_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shapiro(wtl_len_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shapiro(wtl_len_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Due to the size of the p-value (the second value) seen above. I can conclude that the dependant variable is normally distributed. If the p-value was less than 0.05 the dependant value would not be normally distributed [7]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### The next thing I now need to do is check for homogenity of variance. I will do this using the Levenes test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.levene(wtl_len_one,wtl_len_two, wtl_len_three )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing as the above p-value is greater than 0.05 this indicates that there is homogenity of variance among the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### All assumption have been met and I have determined that this dataset is suitable to carry out a one-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.f_oneway(wtl_len_one,wtl_len_two, wtl_len_three )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A p-value here of less than 0.05 means that there is a 'significant difference between our group mean'. Based on this I have enough evidence to reject the null hypthosis, this being that weightloss is not linked to any of the particular diets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### I will now use a tukey post hoc test in order to determine which group has the greatest variability out of the three groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey= pairwise_tukeyhsd(endog = dependant, groups = independant, alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tukey.plot_simultaneous()\n",
    "plt.vlines(x=4.3, ymin =-0.5,ymax=4.5, color = \"red\")\n",
    "tukey.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen from the above Tukey posthoc test it can be seen that there are now statistically significant differences between Diet 1 and Diet 2 and thus from the summary table above I am advised to not reject the null hypothesis. There is however significant differences between diet 1 and diet 2 and also between diet 1 and diet 3 and thus the generated table advises that I should reject the null hypothesis based on the p-value as seen in column 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Two-way ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two or more independant variables with a single dependant variable. For this example the independant variables I have chosen will be diet, age and gender. From the previous tests we have already determined that the Diet dataset is suitable to perform an ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I start by importing the statmodels.api package.\n",
    "import statsmodels.api as sm\n",
    "# I then import the ols package from statsmodels.formula.api.\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I create the model variable that I will use as an argument for the two-way ANOVA function.\n",
    "# For the below example I will be looking at Age and preweight to see if they are related to weightloss6weeks\n",
    "model= ols('weightloss6weeks ~ Age +preweight + Age*preweight', data = df).fit()\n",
    "sm.stats.anova_lm(model, typ= 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen from the outcome above the p-values for both Age and preweight  are greater than 0.05 and thus this would show that both these factors on their own do not have a significant effect on the weight loss after 6 weeks. The p-value for the interaction effect (Age:preweight) is less than 0.05. This would mean that there is a significant interaction effect between the samples age and preweight. The interaction effect shows the effect that one variable has on another variable. In the case of this dataset these results would make sense. Generally the older a person is the least active they become and thus end up gaining more weight due to inactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the example below I will be looking a three different indepenant variables and how they relate to weightloss6weeks.\n",
    "model= ols('weightloss6weeks ~ Diet+gender + Diet*gender', data = df).fit()\n",
    "sm.stats.anova_lm(model, typ= 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As can be seen from the outcome above the p-values for Diet is much less than 0.05. This was already observed in the one-way ANOVA. The p-value for gender is greater than 0.05 and thus this would show that the independant variable gender is not statistically significant. The p-value for the interaction effect Diet:gender is also greater than 0.05. This would mean that there is no significant interaction effect between the samples gender and diet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To conclude the scipy.stat module is very useful in carrying out statistical analysis on datasets. This would make this package a very useful tool in areas such as scientific research and engineering.  Due to the fact that scipy is open source, it is continuoulsy being updated to provide even more tools making the area of statistical analysis much more useable by amateur programmers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\tScipy.org. (2019). Statistical functions (scipy.stats) — SciPy v1.3.3 Reference Guide. [online] Available at: https://docs.scipy.org/doc/scipy/reference/stats.html.\n",
    "####  2.\tNumpy.org. (2009). NumPy — NumPy. [online] Available at: https://numpy.org/ [Accessed 3 Dec. 2021].\n",
    "#### 3.\tMatplotlib (2012). Matplotlib: Python plotting — Matplotlib 3.1.1 documentation. [online] Matplotlib.org. Available at: https://matplotlib.org/ [Accessed 3 Dec. 2021].\n",
    "#### 4.\tPydata.org. (2012). seaborn: statistical data visualization — seaborn 0.9.0 documentation. [online] Available at: https://seaborn.pydata.org/ [Accessed 5 Dec. 2021].\n",
    "#### 5.\tPandas (2018). Python Data Analysis Library — pandas: Python Data Analysis Library. [online] Pydata.org. Available at: https://pandas.pydata.org/ [Accessed 3 Dec. 2021].\n",
    "#### 6.\tMaths hands on with Python, M.H. on (2020). How to perform Analysis of Variance (ANOVA) | One-way and Two-way ANOVA with Python. [online] www.youtube.com. Available at: https://www.youtube.com/watch?v=AhZ-hllEVxs [Accessed 10 Dec. 2021]. \n",
    "#### 7.\tLaerd Statistics (2018). One-way ANOVA in SPSS Statistics - Step-by-step procedure including testing of assumptions. [online] Laerd.com. Available at: https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php [Accessed 10 Dec. 2021]. \n",
    "#### 8.\tUniversity of Sheffield (n.d.). Datasets for teaching - Statistics - MASH - The University of Sheffield. [online] www.sheffield.ac.uk. Available at: https://www.sheffield.ac.uk/mash/statistics/datasets [Accessed 10 Dec. 2021].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
